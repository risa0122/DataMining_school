---
title: "recipe/train(CLS)"
output: 
  html_document:
    fig_width: 7
    fig_height: 5
    fig_caption: true
    theme: yeti
    highlight: kate
    toc: true
    toc_float: true
    toc_depth: 3
    #number_sections: true
    #df_print: paged
    #code_folding: show
---

* casestudy-df2015na-RegByRecipes => casestudy01-df2015na-CLS-recipe-style => 수정
* [Caret Package – A Practical Guide to Machine Learning in R](https://www.machinelearningplus.com/machine-learning/caret-package/)
* [Caret and Tidymodels](https://ryjohnson09.netlify.com/post/caret-and-tidymodels/)
* [https://mdneuzerling.com/post/user-recipes-for-data-processing/](https://mdneuzerling.com/post/user-recipes-for-data-processing/)
* [Exploring the caret package](http://rstudio-pubs-static.s3.amazonaws.com/251240_12a8ecea8e144fada41120ddcf52b116.html)


* 총 36분 소요 (절전기능 끌 것)

```{r}
time1 <- Sys.time()
time1
```


# 자료설명 
* Size Korea 2015년 인체계측자료 일부: n=300 (nc=269), d=13

변수|설명          
----|------------
gnd | 성별{F, M}. 이진 판별분석시 타겟  
age | 나이 
ht  | 키 (cm). 회귀분석시 타겟
wt  | 몸무게 (kg)
wa  | 허리둘레(cm) 
hdln| 손길이(cm)
hdwd| 손너비(cm)
ftln| 발길이(cm)
ftwd| 발너비(cm)
bld | 혈액형{A,AB,B,O}
lft | 왼손잡이용 가변수 (1,0) 
smk | 흡연 여부 (1,0)
alc | 음주 여부 (1,0)

* [Model Lookup](https://topepo.github.io/caret/available-models.html)
* install.packages("caret", dependencies = c("Depends", "Suggests"))


## 참고 사이트: 
* [RStudio Cheat Sheets](https://rstudio.com/resources/cheatsheets/): 최신 치트시트 
* [Data Visualization Cheat Sheet](https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf)
* [Data Transformation Cheat Sheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf)
* [ggplot2 사이트](http://docs.ggplot2.org/current/)


# 패키지 

```{r}
suppressWarnings(suppressMessages(library(tidyverse)))
suppressWarnings(suppressMessages(library(tidymodels)))
suppressWarnings(suppressMessages(library(caret)))
suppressWarnings(suppressMessages(library(gridExtra))) # grid.arrange(,nrow,ncol)
library(scales)    # scale_x_xxx
library(naniar)
```

# 자료읽기

# 읽기

```{r}
# as.data.frame으로 안바꾸면 caret vs tidyverse 호환문제 때문에 많은 경고문 발생 
# as.data.frame 해도 문자변수를 factor화 하지 않음 
DF <- as.data.frame(read_csv('/Users/jongeun/Documents/data_mining/df2015na.csv'))
dim(DF)
sapply(DF, class)
head(DF)
```



# 결측
* 결측 현황: naniar

```{r}
# 변수별 결측비율, Missing=결측셀비율, Present=비결측셀비율 
naniar::vis_miss(DF) 
naniar::miss_var_summary(DF)

# 비결측셀 비율 = 비결측셀 수/셀수 = n. 셀수= n*d 
100*sum(!is.na(DF))/(nrow(DF)*ncol(DF)) 
100*n_complete(DF)/(nrow(DF)*ncol(DF))  
100*prop_complete(DF)

# 결측셀 비율 = 결측셀/셀수
100*sum(is.na(DF))/(nrow(DF)*ncol(DF))  # 결측비율 
100*n_miss(DF)/(nrow(DF)*ncol(DF))      # 결측비율 
100*prop_miss(DF)

# 완전한 관측값 비율=완전한 관측값/n
sum(complete.cases(DF))/nrow(DF)*100  # prop_complete_case(DF)
```

* 결측 현황(표본추출): 원자료가 많으면 랜덤 추출해서 파악 권장 

```{r}
DF %>% sample_n(200) %>% vis_miss()
DF %>% sample_n(200) %>% miss_var_summary()
```


# 전처리 
* 문자변수(gnd, 를 factor화
* {0,1}로 코딩 가변수는 그대로 숫자형으로 사용. factor화해도 무방 

```{r}
# factor로 다 바꿀 것. lm, rpart, rf은 안해도 무방, gbm에서 오류남
DF <- mutate(DF, gnd=factor(gnd), bld=factor(bld))
sapply(DF, class)
```
* 참고: 가변수코딩된 이진변수
    * 일반적으로 R에서는 문제 안됨.
    
```
# 1단계: 모든 명목형 변수는 factor화
DF2 <- mutate(DF, gnd=factor(gnd), bld=factor(bld),        
                 lft=factor(lft), smk=factor(smk), alc=factor(alc))
# 2단계: 수준이 숫자인 factor의 수준이 문자가 되도록 수정: {0,1} => {X0, X1} 
DF2 <- mutate(DF2, lft=factor(lft, labels=c('X0','X1')),
                   smk=factor(smk, labels=make.names(levels(smk))),
                   alc=factor(alc, labels=make.names(levels(alc))))
```


# 탐색 
## 단변량 탐색 

```{r}
summary(DF)
# summarize_if(.tbl, .predicate:logical, .funs:list, ...)
# summarize_at(,tbl, .vars:vector. .funs:list, ...)
summarize_if(DF, is.numeric, list(mn=mean, sd=sd), na.rm=TRUE)
summarize_at(DF, c('ht','wt'), list(mn=mean, sd=sd), na.rm=TRUE)
```

```{r}
g1 <- ggplot(DF, aes(x=ht)) + geom_density() + geom_rug()
g2 <- ggplot(DF, aes(x=ht)) + geom_histogram(color='black', fill='white')

g3 <- ggplot(DF, aes(x=ht)) + 
       geom_histogram(aes(y=..density..), color='black', fill='white') +
       geom_density(alpha=0.2, fill='#FF6666') + 
       geom_rug()
g4 <- ggplot(DF, aes(x=ht)) + geom_boxplot() 
grid.arrange(g1, g2, g3, g4, nrow=2, ncol=2)

g1 <- ggplot(DF, aes(x=gnd)) + geom_bar()
g2 <- ggplot(DF, aes(x=gnd)) + 
        geom_bar(aes(y=..count../sum(..count..))) +
        scale_y_continuous(labels=percent)
g3 <- ggplot(DF, aes(x=smk)) + geom_bar()
g4 <- ggplot(DF, aes(x=smk)) + 
        geom_bar(aes(y=..count../sum(..count..))) +
        scale_y_continuous(labels=percent)
grid.arrange(g1, g2, g3, g4, nrow=2, ncol=2)
```

## 이변량 탐색
###  연속 ~ 이산 

```{r}
DF %>% 
  group_by(gnd) %>% 
  summarize_at(c('ht','wt'), list(mn=mean, sd=sd), na.rm=TRUE)

DF %>% 
  group_by(gnd) %>% 
  summarize_if(is.numeric, list(mn=mean, sd=sd), na.rm=TRUE)
#[I won't grow up](https://www.youtube.com/watch?v=KH71jKtljPE)


g1 <- ggplot(DF, aes(x=ht, col=gnd, fill=gnd)) + geom_density(alpha=0.5)
g2 <- ggplot(DF, aes(x=ht, col=gnd, fill=gnd)) + geom_histogram(alpha=0.5)
g3 <- ggplot(DF, aes(x=ht)) + geom_histogram() + facet_grid(gnd~.)
g4 <- ggplot(DF, aes(x=gnd, y=ht)) + geom_boxplot() + coord_flip()
grid.arrange(g1, g2, g3, g4, nrow=2, ncol=2)
```



```{r}
t.test(ht~gnd, data=DF, var.equal=TRUE)
summary(aov(ht~bld, data=DF))
```

###  연속 ~ 연속

```{r}
R <- cor(DF[,sapply(DF, is.numeric)], use='pairwise.complete.obs')
R
sort(R['ht',], decreasing=TRUE)

g1 <- ggplot(DF, aes(x=ftln, y=ht)) + geom_point(alpha=0.5)
g2 <- ggplot(DF, aes(x=ftln, y=ht, color=gnd, shape=gnd)) + geom_point(alpha=0.5)
g3 <- ggplot(DF, aes(x=smk, y=ht, color=gnd, shape=gnd)) + geom_point(alpha=0.5)
g4 <- ggplot(DF, aes(x=smk, y=ht, color=gnd, shape=gnd)) + geom_jitter(alpha=0.5)
grid.arrange(g1, g2, g3, g4, nrow=2, ncol=2)

library(GGally) # ggcorr, ggparis
ggcorr(DF[,sapply(DF, is.numeric)], 
       geom = 'tile',                # nbreaks=9, palette='RdYlGn',
       label=TRUE)

ggpairs(DF, 
        columns=c('ht','ftln','hdln','ftwd','hdwd', 'wt'),
        lower=list(continuous=wrap('points', alpha=0.05, col='blue')),
        diag=list(continuous='barDiag'))   # diag=list(continous='densityDiag')

ggplot(DF, aes(x=wt, y=ht))+ geom_density2d() + geom_point(aes(col=gnd, shape=gnd))
```
             
### 이산 ~ 이산

```{r}
g1 <- ggplot(DF, aes(x=smk, fill=gnd)) + geom_bar()
g2 <- ggplot(DF, aes(x=smk, fill=gnd)) + geom_bar(aes(y=..count../sum(..count..)))

# Or
tb <- table(DF$gnd, DF$smk)
tb <- xtabs(~smk+gnd, data=DF)
df <- data.frame(tb)
df
g3 <- ggplot(df, aes(x=gnd, y=Freq)) + geom_bar(aes(fill=smk), stat='identity')


tb <- prop.table(xtabs(~gnd+smk, data=DF),1)
tb
df <- data.frame(tb)
df
g4 <- ggplot(df, aes(x=gnd, y=Freq)) + geom_bar(aes(fill=smk), stat='identity')

grid.arrange(g1, g2, g3, g4, nrow=2, ncol=2)
```

```{r}
chisq.test(xtabs(~gnd+smk, data=DF), correct=FALSE)
```

* caret::featurePlot : 분류분석용 시각화 

```{r}
featurePlot(x=DF[,sapply(DF, is.numeric)], y=DF$gnd, 
            plot='box', 
            scales=list(x=list(relation='free'), y=list(relation='free'))) 
```

```{r}
featurePlot(x=DF[,sapply(DF, is.numeric)], y=DF$gnd,
            plot='density', 
            scales=list(x=list(relation='free'), y=list(relation='free'))) 
```



# 분할 
* rsample::initial_split(strata)으로 trn/tst 분할
    * strata: 층화추출시 층화변수지정 
* training(), testing()으로 데이터프레임 추출


```{r}
set.seed(0205)
isp <- initial_split(DF, prop=2/3, strata=gnd) # rset 반환. $in_id가 itrn임 
trn <- as.data.frame(training(isp)) # dataframe 반환
tst <- as.data.frame(testing(isp))  # dataframe 반환
trny <- trn$gnd
tsty <- tst$gnd

# 타겟 비율 
table(trn$gnd)
```

```{r}
table(tst$gnd)
```

```{r}
# 완전한 관측치 비율 확인 
# vapply(trn, function(x) mean(!is.na(x)), numeric(1)) 
sapply(trn, function(x) mean(!is.na(x))) 
```

```{r}
##   gnd   age    ht    wt    wa  hdln  hdwd  ftln  ftwd   bld   lft   smk 
## 1.000 0.970 1.000 0.990 0.980 0.985 0.995 0.990 0.995 0.965 0.985 0.990 
##   alc 
## 0.980

# vapply(trn, function(x) mean(!is.na(x)), numeric(1)) 
sapply(tst, function(x) mean(!is.na(x))) 
```

```{r}
##  gnd  age   ht   wt   wa hdln hdwd ftln ftwd  bld  lft  smk  alc 
## 1.00 0.99 1.00 0.99 0.99 0.97 1.00 0.98 1.00 0.96 0.98 1.00 0.98

featurePlot(x=trn[,sapply(trn, is.numeric)], y=trny, 
            plot='box', 
            scales=list(x=list(relation='free'), y=list(relation='free'))) 
```

```{r}
featurePlot(x=trn[,sapply(trn, is.numeric)], y=trny, 
            plot='density', 
            scales=list(x=list(relation='free'), y=list(relation='free'))) 
```




    
# 전처리
* recipe 객체(전처리 모형) 생성: `RC <- trn %>% recipe(y~.) %>% ... %>% step_XXX()`
* recipe 객체 활용
    * 방법1(juice and bake): 전처리를 적용하여 데이터를 직접 생성 
    * 방법2(juice and bake 안 함) : 데이터를 직접 생성하지 않음. 분석 중 불필요한 데이터를 생성하지 않으므로 메모리 부담 완화. 권장 
    
* 전처리 
    * 거의 0분산인 변수 제거
    * bagimpute로 모든 입력(요인 및 공변량) 대체
    * 입력간 높은 상관을 유발하는 입력 제거
    * 요인을 가변수로 변환 
    
* [권장순서](http://www.rebeccabarter.com/blog/2019-06-06_pre_processing/): 
    * impute(대체): 요인/수치입력(공변량) 모두 대체하는 bagimpute가 편함
    * transformation(symmetry) 
    * discretize 
    * dummy: 가급적 해석편의를 위해 마지막 단계에 적용. 가변수후 표준화해도 무방하지만  
    * interaction 
    * center/scale/range: 신경망계통 권장 
    * multivariateTrnasformation(PCA, spatialSign) 

* [Should you ever standardise binary variables?](https://stats.stackexchange.com/questions/59392/should-you-ever-standardise-binary-variables)
    * Pampel, Logistic regression:A primer (standardizing dummy variable) p32
    * 가변수의 표준화: {0,1}을 {-p/sqrt(pq), q/sqrt(pq)}로 여전히 이진값을 가짐
    * 해석면에서 가변수 표준화 비추천, 예측모형 적합안정성(신경망계통)면에서는 사용가능     
    
 

## 방법1: juice/bake
* 전처리 모형을 적용하여 구체적인 데이터셋을 생성하는 방법
* 1단계(prepared RC, 준비된 RC): `pRC <- prep(RC, training=trn)`
    * pRC: 전처리에 필요한 통계량을 trn로 추정하여 구체화한 RC객체 생성 
* 2단계: `TRN <- juice(pRC)`
    * pRC로 trn을 실제로 변환
* 3단계: `TST <- bake(pRC, new_data=tst)`
    * pRC로 새로운 자료 tst를 변환한 TST 생성 

```
# 전처리 모형 RC 생성(계획만 정의됨, 실제 계산은 필요할 떄 실행함)
RC <- recipe(y~., data=trn) %>%               # 모형식과 훈련용 자료지정한 recipe생성 
  step_nzv(all_predictors()) %>%              # nzv(거의 0분산) 입력제거
  step_corr(all_predictors(), threshold=0)%>% # 입력간 높은 상관을 유발하는 입력제거 
  step_YeoJohnson(all_predictors()) %>%       # 입력에 대한 정규성 멱변환 
  step_interact(~ nbasic:rotatablebonds) %>%  # 교호작용 포함 
  step_center(all_predictors()) %>%           # 중심화
  step_scale(all_predictors()) %>%            # 척도화  
  step_pca(all_predictors(), num = 3)         # 주성분변환 

# pRC(prepared RC: 전처리시 필요한 통계량을 trn으로 계산하여 구체화한 RC) 생성 
pRC <- prep(RC, training=trn)  

# juice(pRC): pRC를 trn에 적용한 TRN 반환 
TRN <- juice(pRC)

# bake(pRC, new_data): pRC를 새로운 자료 tst에 적용한 TST 반환 
TST <- bake(pRC, new_data=tst)
```

## 방법2: recipe 직접 사용
* juice/bake하지 않고 recipe를 그대로 사용. 분석과정 중 불필요한 데이터 생성을 방지 

```{r}
RC <- trn %>%
  recipe(gnd~.)%>%
  #step_nzv(all_predictors())
  #step_medianimpute(all_numeric(),-all_outcomes())%>%
  step_bagimpute(all_predictors())%>%
  #step_corr(all_predictors(),-all_nomial())%>%
  #step_range(all_numeric(),-all_outcomes())%>%
  #step_center(all_numeric(),-all_outcomes())%>%
  #step_scale(all_numeric(),-all_outcomes())%>%
  step_dummy(all_predictors(),-all_numeric())
  
RC  
```


# trainControl: 튜닝 계획 
## 1. 재표본 방식 결정
* 별도의 val없이 trn을 재표본(resampling) 방법으로 모형을 튜닝 
* `trainControl(method, number, repeats,... )`
    * `method='boot|cv|repeatedcv|LOOCV|none'`: 기본 붓스트랩. cv나 repeatedcv 많이 씀 
    * `number`: cv에서 fold(겹) 수
    * `repeats`: cv 반복수 
    

## 2. 성능평가 기준결정 
* `trainControl(summaryFunction, classProbs)`: 튜닝시 성능평가 기준 지정 
    * `train(metric)` 에서 metric과 연동됨.
    * `search='grid|random'`: 초모수 탐색방법 
    * `summaryFunction=defaultSummary`: 모형평가 성능측도. REG:`RMSE/Rsquared`, CLS:`Accuracy/Kappa`). `train(.., metric=)`과 연동됨.
    * `classProbs=F`: ROC나 리프트 분석처럼 확률예측값이 필요한 경우 TRUE로 지정
    * `sampling='none|down|up|smote|rose'`: 클래스 불균형 완화용 표본추출. 재표본된 데이터 적용됨 
    * `verboseIter=T`: 중간과정 출력여부 


trC(summaryFunction)|train(metric='성능측도')      | 참고
-------------------|------------------------------|---------------------------------------
defaultSummary(REG)   |**RMSE**\|Rsquared\|MAE   |RMSE와 Rsquared는 동일기준 
defaultSummary(이진)  |**Accuracy**\|Kappa       |클래스 불균형이면 'Kappa' 추천 
twoClassSummary(이진) |**ROC**\|Sens\|Spec        |ROC:ROC의 AUC. classProbs=T. lift시 편리   
prSummary(이진)       |**AUC'**\|Precision\|Recall\|F|pr분석. AUC:pr의 AUC. 컷오프=0.5, 첫수준이 이벤트(glm은 첫수준이 참조, 마지막이 이벤트임)
defaultSummary(다진)  |**logLoss**\|Mean_AUC\|Accuracy\|Kappa\|...|multiClassSummary와 동일. macro 평균(1 vs all). classPRobs=F면 logloss등 결측됨. 
mnLogLoss(다진)       |**logLoss**\|Mean_??? where ???:Sensitivity..|다항분포의 -logL(상수항제외). 이탈도. classProbs=T.


* 참고: Macro vs Micro Average
    * [Micro-average vs Macro-average of Performance metrics](https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin)
    * macro: compute the metric for each class/take the average (treating all classes equally)
    * micro: aggregate the contributions of all classes to compute the average metric
    * micro is preferable if class imalanced (??)


## 3. 탐색방법 결정 
* `trainControl(search)` 와 `train(tuneGrid, tuneLength)`로 결정  
* 방법 0: `trainControl(..method='none'..)` 
    * `train(..tuneLength=1..)` 에 해당. 튜닝안함 
* 방법 1(tuneGrid지정): 사용자가 초모수값을 데이터프레임으로 제공 
    * `trainControl(search='grid'), train(tuneGrid:data.frame)`
    * 튜닝할 초모수가 적을 때 사용 (대부분의 모형은 평균 2개의 초모수를 가짐)
    * 단점: 초모수값을 구체적으로 정하기 어려움 
* 방법 2(tuneLength지정): 초모수 탐색에 대한 간격을 지정
    * `trainControl(search='grid'), train(tuneLength=10)`
    * 튜닝할 초모수가 적을 때 사용 
    * 예: 초모수가 3개, tuneLength=5면 초모수별로 5개의 값(caret이 범위와 간격 자동결정), 즉 총 5x5x5개의 조합을 탐색함. 
    * 장점: 초모수값의 적절한 범위 자동 탐색. 탐색에 유용  
* 방법 3: 랜덤탐색 
    * `trainControl(search='random'), train(tuneLength=10)`  
    * 튜닝할 초모수가 많을 때 적합 (예:신경망 계통 모형). 정해진 그리드에 대해 랜덤으로 평가 


## `trainControl(), train()` 사용예
* 분류분석시 유의사항: 이벤트 수준과 참조수준 
    * R은 이산형 변수를 처리할 때 첫번째 수준을 참조수준으로 처리함
    * 이산형 입력: 첫번째 수준이 참조수준이 되어 제어군이 됨 
    * 이산형 타겟: 첫번째 수준이 참조, 두 번째 수준이 이벤트 수준임. log(P(이벤트)/P(참조))
    * 라이브러리마다 다름. 예: consuionMatrix, multiClassSummary는 첫수준을 이벤트로 간주. positive를 명확히 지정할 것.
    

    
```
# 회귀분석 RMSE기준 10-fold cv
trCtrl <- trainControl(method='cv', number=10)
M      <- train(...)

# 회귀분석 MAE기준 10-fold cv
trCtrl <- trainControl(method='cv', number=10)
M      <- train(..., metric='MAE', ...)

# 이진타겟 Accuracy기준 10-fold cv (summaryFunction=defaultSummary)
trCtrl <- trainControl(method='cv', number=10) # tr(metric='Accuracy')연동. Accuracy/Kappa
M <- train(...)                                # metric='Accuracy'가 기본값 

# 이진타겟 Kappa기준 10-fold cv (summaryFunction=defaultSummary)
trCtrl <- trainControl(method='cv', number=10) # tr(metric='Kappa')연동. Accuracy/Kappa
M <- train(..., metric='Kappa' ...)            

# 이진타겟 ROC(AUC)기준 10-fold cv
trCtrl <- trainControl(method='cv', number=10, 
                       summaryFunction=twoClassSummary,# tr(metric='ROC')연동. ROC/Sens/Spec
                       classProbs=TRUE)                # 이진분류에서 ROC 등 사용시 필요
M <- train(..., metric='ROC') 

# 이진타겟 Sens 기준 10-fold cv
trCtrl <- trainControl(method='cv', number=10, 
                       summaryFunction=twoClassSummary,# tr(metric='ROC')연동. ROC/Sens/Spec
                       classProbs=TRUE)                # 이진분류에서 ROC 등 사용시 필요
M <- train(..., metric='Sens') 

# 초모수가 결정된 경우
trCtrl <- trainControl(method='none', ..)
```


## 튜닝계획 지정 
* ROC 기준 10겹 교차타당성

```{r}
trCtrl <- trainControl(
  method = 'cv', number=10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE
)
```




# 모형적합
* 용어
    * 명목형 타겟값, y의 클래스값 
    * labeled data(레이블이 있는 자료), 명목형 타겟이 있는  자료 

* 참조수준 

입력측도|참조수준의미|R:첫번째 수준|SAS:마지막 수준
-----|----------|-------------|--------------
명목입력|타겟평균의 수준별 비교시 |j수준과 첫수준간 타겟평균차이| j수준과 끝수준간 타겟평균차이
&nbsp;  |대조군 수준control|$\alpha_j = \mu_j-\mu_1, \alpha_1\equiv 0$|$\alpha_j = \mu_j-\mu_a, \alpha_a\equiv0$
이진타겟|로짓의 기준수준|$Y \in \{\mathbf{0},1\}: \log\frac{P(Y=1)}{P(Y=\mathbf{0})}$|$Y \in \{0,\mathbf{1}\}: \log\frac{P(Y=0)}{P(Y=\mathbf{1})}$
&nbsp;  |분모확률,실패수준|첫수준이 REF(실패), 끝수준이 EVENT(성공)|첫수준이 EVENT(성공), 끝수준이 REF(실패)
&nbsp;  |유의사항| {0,1}코딩 타겟의 1을 모형화. 통계학과 일치|{0,1}코딩 타겟의 0을 모형화. 통계학의 역. 
명목타겟|로짓의 기준수준|$Y\in\{\mathbf{A},H,M\}: \log\frac{P(H)}{P(\mathbf{A})},\log\frac{P(M)}{P(\mathbf{A})}$|$Y\in\{A,H,\mathbf{M}\}: \log\frac{P(A)}{P(\mathbf{M})},\log\frac{P(H)}{P(\mathbf{M})}$


## 분류분석 성능평가 
### 오분류표 
* 오분류 행렬(confusion matrix): 실제 클래스값 y와 클래스 예측값 yhat의 교차표. 수준수가 K면 KxK 분할표 
* 참고: 행과 열, 성공과 실패의 지정이 중요   
    * TF1(To-From with 1st as event): caret방식. 의학 표준. SAS({0:성공, 1:실패(참조)})방식  
    * TF2(To-From with 2nd as event): R 로짓방식{0, 1(성공)}
    * FT1(From-To with 1st as event): MLmetrics방식. SAS({0:성공, 1:실패(참조)})방식  
    * FT2: From-To with 2nd as event: R 로짓방식{0, 1(성공)}
* 표기권장: 
    * 결론1: caret::confusionMatrix기준으로 행(yh) vs 열(y)로 통일.
    * 결론2: 성공수준은 positive= 로 지정. 로짓기준:첫수준(0)을 참조, 끝수준(1)을 성공으로 처리
    * 예: caret::confusionMatrix(yh, y, positive=, mode=)
* 참고: Event classification Table:{FN(1,1), TN(1,2), FP(2,1), TP(2,2)} 제공 


패키지/함수|행|열|성공수준|권장사용예
---------------|----|----|-----------|--------------------
`caret::confusionMatrix(yh, y,..)`|Prediction(yh)|Reference(y)|첫수준=성공|`confusionMatrix(tstyh, tst$y, positive='1')`
`MLmetrics::ConfusionMatrix(yh, y)`|y_true(y)|y_pred(yh)|첫수준=성공(확인요망)|` ConfusionMatrix(tstyh, tst$y)`. table(tst$y, tstyh)만 제공(불필요)


* 사용예 

```
# 오분류표 (From-to 방식으로 직접 생성)
table(trn$y, trnyh)
xtabs(~y+yhglm, data=TRNOUT)


# caret::confusionMatrix(yh, y, mode, positive)
# mode='sens_spec|prec_recall|everything', 
# positive=첫번째 수준(F). 두번째 수준(M)으로 변경해야 sens, spec, prec가 맞음 
confusionMatrix(data=TRNOUT$yhglm, 
                reference=TRNOUT$y, 
                mode='everything', positive='M') 

confusionMatrix(TSTOUT$yhglm, TSTOUT$y, mode='everything', positive='M')

sensitivity(confusionMatrix(yh, y)$table, positive='M')
```


### ROC 분석
* [참고: Choosing Logisitic Regression’s Cutoff value for Unbalanced Dataset](http://ethen8181.github.io/machine-learning/unbalanced/unbalanced.html)
* 확률값을 제공하는 모형의 성능평가 방법
* ROC 정의
    * 컷오프값을 0부터 1까지 변경하면서 (x:FPR=1-spec, y:TPR=sens)을 계산/시각화 
    * 최적의 ROC: 정사각형. AUC=1 
    * Baseline ROC: 45도선 아래 삼각형. AUC=0.5
* AUC(Area Under Curve): ROC곡선아래 면적. [0(최악), 0.5(baseline), 1(최고 성능)]  
* 최적 컷오프 결정 
    * closet.topleft: 최고 성능점(0,1)에서 가장 가까운 ROC상의 점. `min (1-spec)^2+(1-sens)^2`
    * youden: 45도선(baseline)과 최대 수직거리에 엤는 ROC상의 점. max sens+spec-1
    * 참고: trn에서 최적컷오프를 정하고 tst에서 평가해야 함. tst에서 최적은 의미없음 
* ROC분석용 패키지: pROC(권장), ROCR
    * pROC:: roc, auc with CI, multiclass, coords, ggroc, plot.roc, partial roc, 
    * ROCR:: performance(acc,err,sens_spec, prec_recall, phi, odds, auc, lift), ROCR, prediction

* `pROC::roc(response=y, prediction=ph, levels=..)`
    * levels: {0(실패), 1(성공)}로 처리 
    * sensitivies, specificities, threshold, auc 등 반환. 용량이 큼 
* `plot(roc객체,..)`(권장), ggroc(roc객체)
    * print.auc=F: T면 AUC를 출력(권장)
    * legacy=F: T면 x:1-spec vs y:sens 로 표시함(권장) 
    * print.thres='best': 최적 컷오프 출력 
    * print.thres.best.method='youden|closest.topleft': 컷오프 선정기준. 

* `coords(roc, x=, ..)`    
    * x='best': 최적 컷오프 탐색
    * ret=c('thres','spec','sens'): ('thres','acc','spec','sens','prec','fpr') 가능  
    * best.method='youden|cloest.topleft':
    * transpose=F: 경고없애려면 T로 설정
    * FT2형식 ('thres','spec','sens','prec','fpr','tn'(1,1),'fp'(1,2),'fn'(2,1),'tp'(2,2))
    * TF1형식 ('thres','spec','sens','prec','fpr','tn'(1,1),'fn'(1,2),'fp'(2,1),'tp'(2,2))
    
* 사용예

```
library(pROC)
ROC <- roc(TRNOUT$y, TRNOUT$yhglm) 
plot(ROC, legacty=TRUE, print.auc=TRUE, print.thres='best') # Youden
crds <- coords(ROC, x='best', ret=c('thr','acc','spec','sens','prec'))
crds$
```


## glm(family=binomial) 

* glm(family=binomial): 이진 로지스틱 회귀모형 
* 다른 분류모형을 평가할 때 기준 모형(baseline)으로 사용됨: 튜닝모수가 없음. 
* [Logistic Regression Tutorial](https://www.machinelearningplus.com/machine-learning/logistic-regression-tutorial-examples-r/)
* [경고:glm.fit: fitted probabilities numerically 0 or 1 occurred](https://discuss.analyticsvidhya.com/t/glm-fit-fitted-probabilities-numerically-0-or-1-occurred-warning-message-when-i-run-logistic-regression/10390/5). 로짓이 수렴하지 않았거나, 특정 입력에 의해 완전히 분류되어 추정이 불안정하다는 경고

```{r}
modelLookup('glm')
```
```{r}
set.seed(0205)
Mglm <- train(RC,data=trn,
              method='glm', family='binomial',
              metric = 'ROC',
              trControl = trCtrl)
```
```{r}
Mglm$resample
```
```{r}
Mglm
```
```{r}
# g1 <- ggplot(Mglm)
Mglm$bestTune
```
```{r}
Mglm$finalModel
```
```{r}
summary(Mglm$finalModel)
```
```{r}
varImp(Mglm)
```
```{r}
g2 <- ggplot(varImp(Mglm))
Mglm$resample
```
```{r}
g3 <- densityplot(Mglm)
```
* 예측값, 잔차 저장

```{r}
TRNOUT <- data.frame(y=trn$gnd)
TRNOUT <- mutate(TRNOUT,
                 yhglm = predict(Mglm,newdata = trn,type='raw'),
                phglm = predict(Mglm,newdata = trn,type='prob')[,'M'] )
head(TRNOUT)
```
```{r}
TSTOUT <- data.frame(y=tst$gnd)
TSTOUT <- mutate(TSTOUT,
                 yhglm = predict(Mglm,newdata = tst,type='raw'),
                phglm = predict(Mglm,newdata = tst,type='prob')[,'M'] )
head(TSTOUT)
```

* 성능측도 1: 오분류표(컷오프=0.5) 

```{r}
xtabs(~y+yhglm, data=TRNOUT)
```
```{r}
xtabs(~y+yhglm, data=TSTOUT)
```
```{r}
confusionMatrix(data =TRNOUT$yhglm,
                reference = TRNOUT$y,
                mode = 'everything',
                positive = 'M')
```
```{r}
confusionMatrix(data =TSTOUT$yhglm,
                reference = TSTOUT$y,
                mode = 'everything',
                positive = 'M')
```

* 성능측도 2: pROC::roc(response:y, predictor:yh, levels:타겟수준{실패, 성공})

```{r}
library(pROC)
```
```{r}
ROC <- roc(response=TRNOUT$y, predictor = TRNOUT$phglm, levels = c('F','M'))
```
```{r}
ROC
```
```{r}
auc(ROC)
```
```{r}
TRNROC <- list(glm=ROC)
g4 <- ggroc(TRNROC$glm, legacy=TRUE)+ggtitle('TRNROC(glm)')
ROC <- roc(TSTOUT$y, TSTOUT$phglm, levels = c('F','M'))
```
```{r}
TSTROC <- list(glm=ROC)
TSTROC$glm
```
```{r}
g5 <- ggroc(TSTROC$glm,legacy=TRUE)+ggtitle('TSTROC(glm)')
grid.arrange(g2,g3,g4,g5, ncol=2)
```
```{r}
par(mfrow=c(1,2))
plot(TRNROC$glm, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TRNROC(glm)')
plot(TSTROC$glm, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TSTROC(glm)')
```
```{r}
par(mfrow=c(1,1))
```


* cutoff 결정: 
   * pROC::coords(roc, x=위치|'best', best.method='youden|closest.topleft', transpose=T)
   * ret=c('threshold','accuracy', 'speficity','sensibility','precision')
   * plot(roc) 에서 확인가능

```{r}
crds <- coords(TRNROC$glm, x='best', best.method = 'closest.topleft', transpose = TRUE,
               ret=c('thres','tn','fn','fp','tp','acc','spec','sens','prec'))
crds
```
```{r}
CRDS <- list(glm=crds)
chk <- matrix(c(crds['tn'],crds['fn'],crds['fp'],crds['tp']),nr=2,byrow=T)
dimnames(chk) <- list(c('To -','To +'),c('From -','From +'))
chk
```
```{r}
# trn 최적컷오프를 이용한 분류결과
confusionMatrix(factor(ifelse(TRNOUT$phglm>=CRDS$glm['threshold'],'M','F')),
                TRNOUT$y,
                mode='everything', positive='M')
```
```{r}
# trn 최적컷오프로 tst를 분류한 결과, 주의: tst의 최적컷오프가 아니라 trn의 최적 컷오프 사용
confusionMatrix(factor(ifelse(TSTOUT$phglm>=CRDS$glm['threshold'],'M','F')),
                TSTOUT$y,
                mode='everything', positive='M')
```

## glmStepAIC 
* MASS::stepAIC를 이용한 변수선택 


```{r}
modelLookup('glmStepAIC')
```
```{r}
set.seed(0205)
Mstep <- train(RC,data=trn,
              method='glmStepAIC', direction='backward',
              metric = 'ROC',
              trControl = trCtrl)
```
```{r}
Mstep
```
```{r}
Mstep$bestTune
```

```{r}
varImp(Mstep)
```
```{r}
Mstep$finalModel
```
```{r}
summary(Mstep$finalModel)
```

```{r}
g2 <- ggplot(varImp(Mstep))
Mstep$resample 
```
```{r}
g3 <- densityplot(Mstep)
```

* 예측값, 잔차 저장 및 성능측도 
```{r}
TRNOUT <- mutate(TRNOUT,
                 yhstep = predict(Mstep,newdata = trn,type='raw'),
                phstep = predict(Mstep,newdata = trn,type='prob')[,'M'] )
head(TRNOUT)
```
```{r}
TSTOUT <- mutate(TSTOUT,
                 yhstep = predict(Mstep,newdata = tst,type='raw'),
                phstep = predict(Mstep,newdata = tst,type='prob')[,'M'] )
head(TSTOUT)
```

* 성능측도 1: 오분류표(컷오프=0.5)  
```{r}
confusionMatrix(TRNOUT$yhstep, TRNOUT$y, mode='everything', positive='M')
```
```{r}
confusionMatrix(TSTOUT$yhstep, TSTOUT$y, mode='everything', positive='M')
```

* 성능측도 2: pROC::roc(response:y, predictor:yh, levels:타겟수준{실패, 성공})

```{r}
ROC <- roc(response=TRNOUT$y, predictor = TRNOUT$phstep, levels = c('F','M'))
```
```{r}
ROC
```
```{r}
auc(ROC)
```
```{r}
TRNROC$step <- ROC
g4 <- ggroc(TRNROC$step, legacy.axes=TRUE)+ggtitle('TRNROC(glmStepAIC)')
ROC <- roc(TSTOUT$y, TSTOUT$phstep, levels = c('F','M'))
```
```{r}
TSTROC$step <- ROC
TSTROC$step
```
```{r}
g5 <- ggroc(TSTROC$step,legacy=TRUE)+ggtitle('TSTROC(glm)')
grid.arrange(g2,g3,g4,g5, ncol=2)
```
```{r}
par(mfrow=c(1,2))
plot(TRNROC$step, legacy=TRUE, print.auc=TRUE, print.thres='best', main='TRNROC(glmStepAIC)')
plot(TSTROC$step, legacy=TRUE, print.auc=TRUE, print.thres='best', main='TSTROC(glmStepAIC)')
```
```{r}
par(mfrow=c(1,1))
```
* cutoff 결정 

```{r}
crds <- coords(TRNROC$step, x='best', best.method = 'closest.topleft', transpose = TRUE,
               ret=c('thres','tn','fn','fp','tp','acc','spec','sens','prec'))
crds
```

```{r}
CRDS$step <- crds
chk <- matrix(c(crds['tn'],crds['fn'],crds['fp'],crds['tp']),nr=2,byrow=T)
dimnames(chk) <- list(c('To -','To +'),c('From -','From +'))
chk
```
```{r}
confusionMatrix(factor(ifelse(TRNOUT$phstep>=CRDS$step['threshold'],'M','F')), TRNOUT$y,
                mode='everything', positive = 'M')
```
```{r}
confusionMatrix(factor(ifelse(TSTOUT$phstep>=CRDS$step['threshold'],'M','F')), TSTOUT$y,
                mode='everything', positive = 'M')
```




## glmnet,elasticnet,lasso,ridge 
* enet은 분류분석에 사용 못함. glmnet 사용해야 함 


모형|glmnet(alpha:Mix%L1, lambda:정규화모수)|elasticnet::enet(lambda:L2정규화모수)
--------------|------------------------------------|-------------------------------------
L1벌점회귀(lasso)|glmnet(alpha=1, lambda)   |enet(lambda=0)
L2벌점회귀(ridge)|glmnet(alpha=0, lambda)   |enet(lambda=1)
elasticnet       |glmnet(alpha, lambda)     |enet(lambda=0)
참고             |modelLookup('glmnet'): alpha, lambda|modelLookup('enet'): lambda, fraction
분류분석         |family='binomial\|multinomial'|불가 


* glmnet: nlambda=100개를 사전 탐색한 후 lambda를 정함 
* glmnet 목적함수 

$$ \frac{1}{N} \sum_{i=1}^N (y_i-\eta_i)^2 + \lambda\{(1-\alpha) ||\beta||_2^2 + \alpha ||\beta||_1\} $$


모수    |역할(기본값)|참고
-------|---------|------------------------------------
**alpha** |Mixing Percentage L1 비중|alpha=1(lasso), alpha=0(ridge), (0~1)면 elasticnet
**lambda**|Regularization parameter L1 벌점 계수|클수록 회귀계수를 축소시킴(보수적)



```{r}
modelLookup('glmnet')
```
```{r}
set.seed(0205)
Mglmnet <- train(RC,data=trn,
              method='glmnet', family='binomial',
              metric = 'ROC',
              tuneLength = 10,
              trControl = trCtrl)
```
```{r}
Mglmnet
```
```{r}
g2 <- ggplot(varImp(Mglmnet))
Mglmnet$resample
```
```{r}
g3 <- densityplot(Mglmnet)
```
* 예측값, 잔차 저장 및 성능측도 
```{r}
TRNOUT <- mutate(TRNOUT,
                 yhglmnet = predict(Mglmnet, newdata = trn,type='raw'),
                phglmnet = predict(Mglmnet, newdata = trn,type='prob')[,'M'])
head(TRNOUT)
```
```{r}
TSTOUT <- mutate(TSTOUT,
                 yhglmnet = predict(Mglmnet,newdata = tst,type='raw'),
                phglmnet = predict(Mglmnet,newdata = tst,type='prob')[,'M'] )
head(TSTOUT)
```

* 성능측도 1: 오분류표 

```{r}
confusionMatrix(TRNOUT$yhglmnet, TRNOUT$y, positive = 'M')
```
```{r}
confusionMatrix(TSTOUT$yhglmnet, TSTOUT$y, positive = 'M')
```
* 성능측도 2: ROC 

```{r}
ROC <- roc(response=TRNOUT$y, predictor = TRNOUT$phglmnet, levels = c('F','M'))
```
```{r}
ROC
```
```{r}
auc(ROC)
```
```{r}
TRNROC$glmnet <- ROC
g4 <- ggroc(TRNROC$glmnet, legacy=TRUE) + ggtitle('TRNROC(glmnet)')
ROC <- roc(TSTOUT$y, TSTOUT$phglmnet, levels = c('F','M'))
```
```{r}
TSTROC$glmnet <- ROC
auc(TSTROC$glmnet)
```
```{r}
g5 <- ggroc(TSTROC$glmnet, legacy = TRUE) + ggtitle('TSTROC(glmnet)')
grid.arrange(g2,g3,g4,g5,ncol=2)
```
```{r}
par(mfrow=c(1,2))
plot(TRNROC$glmnet, legacy = TRUE,
     print.thres='best',
     print.thres.best.method='closest.topleft',
     print.auc = TRUE,
     main = 'TRNROC(glmnet)'
     )
plot(TSTROC$glmnet, legacy = TRUE,
     print.thres='best',
     print.thres.best.method='closest.topleft',
     print.auc = TRUE,
     main = 'TSTROC(glmnet)'
     )
```
```{r}
par(mfrow=c(1,1))
```
* cutoff 결정 

```{r}
crds <- coords(TRNROC$glmnet, x='best', best.method = 'closest.topleft', transpose = TRUE,
               ret=c('thres','tn','fn','fp','tp','acc','spec','sens','prec'))
crds
```
```{r}
CRDS$glmnet <- crds
chk <- matrix(c(crds['tn'],crds['fn'],crds['fp'],crds['tp']),nr=2,byrow=T)
dimnames(chk) <- list(c('To -','To +'),c('From -','From +'))
chk
```

```{r}
confusionMatrix(factor(ifelse(TRNOUT$phglmnet>=CRDS$glmnet['threshold'],'M','F')),
                TRNOUT$y,
                mode='everything', positive='M')
```
```{r}
confusionMatrix(factor(ifelse(TSTOUT$phglmnet>=CRDS$glmnet['threshold'],'M','F')),
                TSTOUT$y,
                mode='everything', positive='M')
```
## nnet 
* nnet: 은닉층이 1개인 MLP 
    * 회귀(linout=TRUE), 이진판별(entropy=TRUE), 다진판별(softmax=TRUE)
    * 규제화: decay. 단 입력이 [0,1]로 범위정규화 되어 있어야 적용가능.회귀면 0.004~0.02(linout=T, 회귀), 0.01~0.1(entropy=T, 이진판별)

모수    |역할(기본값)|참고
-------|---------|------------------------------------
**size**|no(Hidden Units) 은닉층내 노드수|&nbsp;
**decay**| Weight decay L2 벌점계수| 입력을 [0, 1]로 범위정규화했을 때 적용가능 


* 사용시 유의사항
    * nnet: 은닉층 1개만 가능. decay는 입력을 [0,1]정규화 해야함. 상대적으로 안정적으로 수렴함
    * neuralnet: 다층 MLP 가능. decay 사용불가. 요인처리불가. 입력을 [0,1]정규화 권장. 수렴안할 때 많으므로 반드시 예측값을 확인할 것.
    * avNNet: 다수의 nnet을 결합하는 ensemble이므로 초기값 문제는 어느 정도 해결. nnet이 은닉층 1개만 허용하므로 MLP의 장점인 모형 유연성은 기대하기 힘듦
    * 권장: Deep Learning하려면 nnet이나 neuralnet보다 keras를 사용할 것.

```{r}
modelLookup('nnet')
```
```{r}
set.seed(0205)
Mnnet <- train(RC, data=trn,
               method='nnet', maxit=1000, trace=FALSE,
               metric = 'ROC',
               tuneLength = 5,
               trControl = trCtrl)
Mnnet
```
```{r}
g1 <- ggplot(Mnnet)
g1
```
```{r}
Mnnet$bestTune
```
```{r}
Mnnet$finalModel
```
```{r}
varImp(Mnnet)
```
```{r}
g2 <- ggplot(varImp(Mnnet))
Mnnet$resample
```
```{r}
g3 <- densityplot(Mnnet)
```

* 예측값, 잔차 저장 및 성능측도 

```{r}
TRNOUT <- mutate(TRNOUT,
                 yhnnet = predict(Mnnet,newdata = trn,type='raw'),
                phnnet = predict(Mnnet,newdata = trn,type='prob')[,'M'] )
head(TRNOUT)
```
```{r}
TSTOUT <- mutate(TSTOUT,
                 yhnnet = predict(Mnnet,newdata = tst,type='raw'),
                phnnet = predict(Mnnet,newdata = tst,type='prob')[,'M'] )
head(TSTOUT)
```

* 성능측도 1: 오분류표 

```{r}
confusionMatrix(TRNOUT$yhnnet, TRNOUT$y, mode='prec_recall',positive = 'M')
```
```{r}
confusionMatrix(TSTOUT$yhnnet, TSTOUT$y, mode='prec_recall',positive = 'M')
```

* 성능측도 2: ROC 

```{r}
ROC <- roc(response=TRNOUT$y, predictor = TRNOUT$phnnet, levels = c('F','M'))
```
```{r}
ROC
```
```{r}
auc(ROC)
```
```{r}
TRNROC$nnet <- ROC
g4 <- ggroc(TRNROC$nnet, legacy=TRUE)+ggtitle('TRNROC(nnet)')
ROC <- roc(TSTOUT$y, TSTOUT$phnnet, levels = c('F','M'))
```
```{r}
TSTROC$nnet <- ROC
auc(TSTROC$nnet)
```
```{r}
g5 <- ggroc(TSTROC$nnet,legacy=TRUE)+ggtitle('TSTROC(nnet)')
grid.arrange(g2,g3,g4,g5, ncol=2)
```
```{r}
par(mfrow=c(1,2))
plot(TRNROC$nnet, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TRNROC(nnet)')
plot(TSTROC$nnet, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TSTROC(nnet)')
```
```{r}
par(mfrow=c(1,1))
```
* cutoff 결정 

```{r}
crds <- coords(TRNROC$nnet, x='best', best.method = 'closest.topleft', transpose = TRUE,
               ret=c('thres','tn','fn','fp','tp','acc','spec','sens','prec'))
crds
```
```{r}
CRDS$nnet <- crds
chk <- matrix(c(crds['tn'],crds['fn'],crds['fp'],crds['tp']),nr=2,byrow=T)
dimnames(chk) <- list(c('To -','To +'),c('From -','From +'))
chk
```
```{r}
confusionMatrix(factor(ifelse(TRNOUT$phnnet>=CRDS$nnet['threshold'],'M','F')),
                TRNOUT$y,
                mode='everything', positive='M')
```
```{r}
confusionMatrix(factor(ifelse(TSTOUT$phnnet>=CRDS$glm['threshold'],'M','F')),
                TSTOUT$y,
                mode='everything', positive='M')

```

## svmRadial 
* svmRadial: kernlab의 ksvm
    * 타겟이 factor가 아니면 기본값 type='eps-svr'. type='nu-svr'로 변경가능
    * 타겟이 factor면 기본값 type='C-svc'
    
모수  |역할(기본값)|참고
-----|---------|------------------------------------
**C**|Cost|&nbsp;
sigma|sigma|tuneLength 사용시 자동 튜닝에서 제외 


```{r}
modelLookup('svmRadial')
```
```{r}
set.seed(0205)
MsvmRadial <- train(RC,data=trn,
              method='svmRadial',
              metric = 'ROC',
              tuneLength = 10,
              trControl = trCtrl)
```
```{r}
MsvmRadial
```
```{r}
g1 <- ggplot(MsvmRadial)
g1
```
```{r}
MsvmRadial$bestTune
```
```{r}
MsvmRadial$finalModel
```
```{r}
varImp(MsvmRadial)
```
```{r}
g2 <- ggplot(varImp(MsvmRadial))
MsvmRadial$resample
```
```{r}
g3 <- densityplot(MsvmRadial)
```
* 예측값, 잔차 저장 및 성능측도 
```{r}
TRNOUT <- mutate(TRNOUT,
                 yhsvmRadial = predict(MsvmRadial,newdata = trn,type='raw'),
                phsvmRadial = predict(MsvmRadial,newdata = trn,type='prob')[,'M'] )
head(TRNOUT)
```
```{r}
TSTOUT <- mutate(TSTOUT,
                 yhsvmRadial = predict(MsvmRadial,newdata = tst,type='raw'),
                phsvmRadial = predict(MsvmRadial,newdata = tst,type='prob')[,'M'] )
head(TSTOUT)
```

* 성능측도 1: 오분류표 

```{r}
confusionMatrix(data =TRNOUT$yhsvmRadial,
                reference = TRNOUT$y,
                mode = 'everything',
                positive = 'M')

```
```{r}
confusionMatrix(data =TSTOUT$yhsvmRadia,
                reference = TSTOUT$y,
                mode = 'everything',
                positive = 'M')
```


* 성능측도 2: ROC 

```{r}
ROC <- roc(response=TRNOUT$y, predictor = TRNOUT$phsvmRadial, levels = c('F','M'))

```
```{r}
ROC
```
```{r}
auc(ROC)
```
```{r}
TRNROC$svmRadial <- ROC
g4 <- ggroc(TRNROC$svmRadial, legacy=TRUE)+ggtitle('TRNROC(svmRadial)')
ROC <- roc(TSTOUT$y, TSTOUT$phsvmRadial, levels = c('F','M'))
```
```{r}
TSTROC$svmRadial <- ROC
auc(TSTROC$svmRadial)
```
```{r}
g5 <- ggroc(TSTROC$svmRadial,legacy=TRUE)+ggtitle('TSTROC(svmRadial)')
grid.arrange(g2,g3,g4,g5, ncol=2)
```
```{r}
par(mfrow=c(1,2))
plot(TRNROC$svmRadial, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TRNROC(svmRadial)')
plot(TSTROC$nnet, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TSTROC(svmRadial)')
```
```{r}
par(mfrow=c(1,1))
```

* cutoff 결정 

```{r}
crds <- coords(TRNROC$svmRadial, x='best', best.method = 'closest.topleft', transpose = TRUE,
               ret=c('thres','tn','fn','fp','tp','acc','spec','sens','prec'))
crds

```
```{r}
CRDS$svmRadial <- crds
chk <- matrix(c(crds['tn'],crds['fn'],crds['fp'],crds['tp']),nr=2,byrow=T)
dimnames(chk) <- list(c('To -','To +'),c('From -','From +'))
chk
```
```{r}
confusionMatrix(factor(ifelse(TRNOUT$phsvmRadial>=CRDS$svmRadial['threshold'],'M','F')),
                TRNOUT$y,
                mode='everything', positive='M')
```
```{r}
confusionMatrix(factor(ifelse(TSTOUT$phsvmRadial>=CRDS$svmRadial['threshold'],'M','F')),
                TSTOUT$y,
                mode='everything', positive='M')
```



## rpart 
* rpart (회귀나무) 


모수    |역할(기본값)|참고
--------|------------|------------------------------------
**cp**  |Complexity Parameter(0.01) 단계별 학습 가중치|cp값 이하로 적합도개선하는 가지 제거
    


```{r}
modelLookup('rpart')
```
```{r}
modelLookup('rpart2')
```
```{r}
set.seed(0205)
Mrpart <- train(RC,data=trn,
              method='rpart',
              metric = 'ROC',
              tuneLength = 10,
              trControl = trCtrl)
```
```{r}
Mrpart
```
```{r}
g1 <- ggplot(Mrpart)
g1
```
```{r}
Mrpart$bestTune
```
```{r}
Mrpart$finalModel
```
```{r}
plot(Mrpart$finalModel)
text(Mrpart$finalModel)
```
```{r}
library(partykit)
```
```{r}
plot(as.party(Mrpart$finalModel))
```
```{r}
library(rpart.plot)
rpart.plot::rpart.plot(Mrpart$finalModel)
```
```{r}
varImp(Mrpart)
```
```{r}
g2 <- ggplot(varImp(Mrpart))
Mrpart$resample
```
```{r}
g3 <- densityplot(Mrpart)
```

* 예측값, 잔차 저장 및 성능측도 
```{r}
TRNOUT <- mutate(TRNOUT,
                 yhrpart = predict(Mrpart,newdata = trn,type='raw'),
                phrpart = predict(Mrpart,newdata = trn,type='prob')[,'M'] )
head(TRNOUT)
```
```{r}
TSTOUT <- mutate(TSTOUT,
                 yhrpart = predict(Mrpart,newdata = tst,type='raw'),
                phrpart = predict(Mrpart,newdata = tst,type='prob')[,'M'] )
head(TSTOUT)
```


* 성능측도 1: 오분류표 

```{r}
confusionMatrix(data =TRNOUT$yhrpart,
                reference = TRNOUT$y,
                mode = 'everything',
                positive = 'M')
```
```{r}
confusionMatrix(data =TSTOUT$yhrpart,
                reference = TSTOUT$y,
                mode = 'everything',
                positive = 'M')
```


* 성능측도 2: ROC 

```{r}
ROC <- roc(response=TRNOUT$y, predictor = TRNOUT$phrpart, levels = c('F','M'))
```
```{r}
ROC
```
```{r}
auc(ROC)
```
```{r}
TRNROC$rpart <- ROC
g4 <- ggroc(TRNROC$rpart, legacy=TRUE)+ggtitle('TRNROC(rpart)')
ROC <- roc(TSTOUT$y, TSTOUT$phrpart, levels = c('F','M'))
```
```{r}
TSTROC$rpart <- ROC
auc(TSTROC$rpart)
```
```{r}
g5 <- ggroc(TSTROC$rpart,legacy=TRUE)+ggtitle('TSTROC(rpart)')
grid.arrange(g2,g3,g4,g5, ncol=2)
```
```{r}
par(mfrow=c(1,2))
plot(TRNROC$rpart, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TRNROC(rpart)')
plot(TSTROC$rpart, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TSTROC(rpart)')
```
```{r}
par(mfrow=c(1,1))
```
```{r}
CRDS$rpart <- crds
chk <- matrix(c(crds['tn'],crds['fn'],crds['fp'],crds['tp']),nr=2,byrow=T)
dimnames(chk) <- list(c('To -','To +'),c('From -','From +'))
chk
```
```{r}
confusionMatrix(factor(ifelse(TRNOUT$phrpart>=CRDS$rpart['threshold'],'M','F')),
                TRNOUT$y,
                mode='everything', positive='M')
```
```{r}
confusionMatrix(factor(ifelse(TSTOUT$phrpart>=CRDS$rpart['threshold'],'M','F')),
                TSTOUT$y,
                mode='everything', positive='M')
```
## ranger 
* ranger: fast random forest 

모수    |역할(기본값)|참고
--------|------------|------------------------------------
**mtry**|no(Randomly Selected Predictors)|분지에 사용할 입력수. mtry>d면 오류 발생. tuneGrid로 조정
**splitrule**|Splitting rule {variance, extratrees}|&nbsp;
**min.node.size**|Min Node Size (5)|&nbsp;


```{r}
modelLookup('ranger')
```
```{r}
set.seed(0205)
rangerGrid <- expand.grid(
  mtry = seq(2,12-1, by=2),
  splitrule = c('gini','extratrees'),
  min.node.size = 1:3
)
Mranger <- train(RC,data=trn,
              method='ranger', importance='impurity',
              metric = 'ROC',
              tuneGrid = rangerGrid,
              trControl = trCtrl)

```
```{r}
Mranger
```
```{r}
g1 <- ggplot(Mranger)
g1
```
```{r}
Mranger$bestTune
```
```{r}
Mranger$finalModel
```
```{r}
varImp(Mranger)
```
```{r}
g2 <- ggplot(varImp(Mranger))
Mranger$resample
```
```{r}
g3 <- densityplot(Mranger)
```
* 예측값, 잔차 저장 및 성능측도 
```{r}
TRNOUT <- mutate(TRNOUT,
                 yhranger = predict(Mranger,newdata = trn,type='raw'),
                phranger = predict(Mranger,newdata = trn,type='prob')[,'M'] )
head(TRNOUT)
```
```{r}
TSTOUT <- mutate(TSTOUT,
                 yhranger = predict(Mranger,newdata = tst,type='raw'),
                phranger = predict(Mranger,newdata = tst,type='prob')[,'M'] )
head(TSTOUT)
```

* 성능측도 1: 오분류표 

```{r}
confusionMatrix(data =TRNOUT$yhranger,
                reference = TRNOUT$y,
                mode = 'everything',
                positive = 'M')
```
```{r}
confusionMatrix(data =TSTOUT$yhranger,
                reference = TSTOUT$y,
                mode = 'everything',
                positive = 'M')
```

* 성능측도 2: ROC 

```{r}
ROC <- roc(response=TRNOUT$y, predictor = TRNOUT$phranger, levels = c('F','M'))
```
```{r}
ROC
```
```{r}
auc(ROC)
```
```{r}
TRNROC$ranger <- ROC
g4 <- ggroc(TRNROC$ranger, legacy=TRUE)+ggtitle('TRNROC(ranger)')
ROC <- roc(TSTOUT$y, TSTOUT$phranger, levels = c('F','M'))
```
```{r}
TSTROC$ranger <- ROC
auc(TSTROC$ranger)
```
```{r}
g5 <- ggroc(TSTROC$ranger,legacy=TRUE)+ggtitle('TSTROC(ranger)')
grid.arrange(g2,g3,g4,g5, ncol=2)
```
```{r}
par(mfrow=c(1,2))
plot(TRNROC$ranger, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TRNROC(ranger)')
plot(TSTROC$ranger, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TSTROC(ranger)')
```
```{r}
par(mfrow=c(1,1))
```
* cutoff 결정 

```{r}
CRDS$ranger <- crds
chk <- matrix(c(crds['tn'],crds['fn'],crds['fp'],crds['tp']),nr=2,byrow=T)
dimnames(chk) <- list(c('To -','To +'),c('From -','From +'))
chk
```

```{r}
confusionMatrix(factor(ifelse(TRNOUT$phranger>=CRDS$ranger['threshold'],'M','F')),
                TRNOUT$y,
                mode='everything', positive='M')
```
```{r}
confusionMatrix(factor(ifelse(TSTOUT$phranger>=CRDS$ranger['threshold'],'M','F')),
                TSTOUT$y,
                mode='everything', positive='M')
```


## xgbTree 
* xgbTree: extreme boosting
* [알고리즘 소개 : XGBoost](https://apple-rbox.tistory.com/6)

모수    |역할(기본값)|참고
-------|-----------------------|------------------------------------
**eta**|Shrinkage (default=0.3) 단계별 학습 가중치|작을수록 보수적(;작은 eta는 큰 rounds에 해당)  
**max_depth**|Max Tree Depth (default=6)  최대 나무 깊이|[0,Inf]. 클수록 방임적 
**colsample_bytree**|Subsample Ratio of Columns (default=1) 나무생성시 사용할 입력변수 비율 | (0,1)
**subsample**|Subsample Percentage  (default=1)|(0,1). 0.5면 적합자료의 반으로 나무생성
**nrounds**|Boosting Iterations|(50,100,150, ...)
gamma=0|Min Loss Reduction|Info Gain계산시 벌점값. 값이 클수록(IG값을 축소) 보수적
min_child_weight=1|Min Sum of Instance Weight|값이 클수록 보수적  


* 참고
   * tuneLength 지정시 eta, max_depth, colsample_bytree, subsample, nrounds를 튜닝. gamma(0), min_child_weight(1)는 고정. tuneLength=5면 2(eta)x5x2(colsample_bytree)x5x5=500. 이유는 ??
   * library(plyr); library(dplyr) 순서로 로딩 권장 경고나옴. 
   * tidyverse를 로딩하면 dplyr만 로딩됨. xgboost가 plyr를 쓰기 때문에 plyr가 뒤에 로딩되고 충돌

```{r}
modelLookup('xgbTree')
```
```{r}
set.seed(0205)
xgGrid <- expand.grid(
  eta=0.3, max_depth=6, colsample_bytree = 1, 
  subsample=1, nrounds=c(10,50,100),
  gamma = 0, min_child_weight=1
)
MxgbTree <- train(RC,data=trn,
              method='glm', family='binomial',
              metric = 'ROC',
              trControl = trCtrl)
```
```{r}
MxgbTree
```
```{r}
#g1 <- ggplot(MxgbTree)
#g1
MxgbTree$bestTune
```
```{r}
MxgbTree$finalModel
```
```{r}
varImp(MxgbTree)
```
```{r}
g2 <- ggplot(varImp(MxgbTree))
MxgbTree$resample
```
```{r}
g3 <- densityplot(MxgbTree)
```

* 예측값, 잔차 저장 및 성능측도 
```{r}
TRNOUT <- mutate(TRNOUT,
                 yhxgbTree = predict(MxgbTree,newdata = trn,type='raw'),
                phxgbTree = predict(MxgbTree,newdata = trn,type='prob')[,'M'] )
head(TRNOUT)
```
```{r}
TSTOUT <- mutate(TSTOUT,
                 yhxgbTree = predict(MxgbTree,newdata = tst,type='raw'),
                phxgbTree = predict(MxgbTree,newdata = tst,type='prob')[,'M'] )
head(TSTOUT)
```

* 성능측도 1: 오분류표 
```{r}
confusionMatrix(data =TRNOUT$yhxgbTree,
                reference = TRNOUT$y,
                mode = 'everything',
                positive = 'M')

```
```{r}
confusionMatrix(data =TSTOUT$yhxgbTree,
                reference = TSTOUT$y,
                mode = 'everything',
                positive = 'M')

```

* 성능측도 2: ROC 

```{r}
ROC <- roc(response=TRNOUT$y, predictor = TRNOUT$phxgbTree, levels = c('F','M'))
```
```{r}
ROC
```
```{r}
auc(ROC)
```
```{r}
TRNROC$xgbTree <- ROC
g4 <- ggroc(TRNROC$xgbTree, legacy=TRUE)+ggtitle('TRNROC(xgbTree)')
ROC <- roc(TSTOUT$y, TSTOUT$phxgbTree, levels = c('F','M'))

```
```{r}
TSTROC$xgbTree <- ROC
auc(TSTROC$xgbTree)
g5 <- ggroc(TSTROC$xgbTree,legacy=TRUE)+ggtitle('TSTROC(xgbTree)')
grid.arrange(g2,g3,g4,g5, ncol=2)
```
```{r}
par(mfrow=c(1,2))
plot(TRNROC$xgbTree, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TRNROC(xgbTree)')
plot(TSTROC$xgbTree, legacy=TRUE, print.auc=TRUE, print.thres='best',main='TSTROC(xgbTree)')
```
```{r}
par(mfrow=c(1,1))
```

* cutoff 결정 

```{r}
crds <- coords(TRNROC$xgbTree, x='best', best.method = 'closest.topleft', transpose = TRUE,
               ret=c('thres','tn','fn','fp','tp','acc','spec','sens','prec'))
crds
```
```{r}
CRDS$xgbTree <- crds
chk <- matrix(c(crds['tn'],crds['fn'],crds['fp'],crds['tp']),nr=2,byrow=T)
dimnames(chk) <- list(c('To -','To +'),c('From -','From +'))
chk
```

```{r}
confusionMatrix(factor(ifelse(TRNOUT$phxgbTree>=CRDS$xgbTree['threshold'],'M','F')),
                TRNOUT$y,
                mode='everything', positive='M')
```
```{r}
confusionMatrix(factor(ifelse(TSTOUT$phxgbTree>=CRDS$xgbTree['threshold'],'M','F')),
                TSTOUT$y,
                mode='everything', positive='M')

```

# 모형평가
## CV로 성능평가: resamples객체 생성 

```{r}
resamp <- resamples(list(Mglm=Mglm,
                         Mstep=Mstep,
                         Mglmnet = Mglmnet,
                         Mnnet = Mnnet,
                         MsvmRadial = MsvmRadial,
                         Mrpart = Mrpart,
                         Mranger = Mranger,
                         MxgbTree = MxgbTree))
summary(resamp)
```
```{r}
bwplot(resamp)
```
```{r}
splom(resamp, metric = 'ROC')
```
```{r}
dresamp <- diff(resamp, metric='ROC')
summary(dresamp)
```

## TRN/TST에서 성능평가 
### AUC 비교
* TRNROC/TSTROC에 roc객체가 리스트로 저장되어 있음
* auc()로 각 모형의 roc객체에서 AUC를 추출하여 AUCtbl에 저장 
* 프로그램 세부사항: 
    * sapply(), map_df() 
    * rbind(), bind_rows()
    
```{r}
#AUC 계산
#TRNROC/TSTROC 에서 AUC 추출
AUCtbl <- bind_rows(
  map_dfr(TRNROC, function(x)as.vector(auc(x))),
  map_dfr(TSTROC, function(x)as.vector(auc(x)))
)

#모향이름과 AUC 결합. 행이 모형, 열{MODEL,TRNAUC,TSTAUC}
AUCtbl <- data.frame(MODEL=colnames(AUCtbl), t(AUCtbl))
rownames(AUCtbl) <- NULL
colnames(AUCtbl) <- c('Model','TRNAUC','TSTAUC')

# TSTAUC 역순 정렬 :{xgbTree,ranger,glmnet,svmRadial,glm,step,rpart,nnet}순
arrange(AUCtbl,desc(TSTAUC))
```


### 컷오프=0.5일 때 오분류표 
* 이진타겟의 기본 컷오프인 0.5에서 성능비교
* TRNOUT/TSTOUT의 yh(컷오프 0.5로 분류한 예측값)로 오분류표 작성


```{r}
cnfmat <- function(yh,y,positive){
  m <- confusionMatrix(yh,y,mode='everything', positive=positive)
  lvls <- levels(yh)
  pos <- positive
  neg <- setdiff(lvls,pos)
  x <- c(tn11 = m$table[neg,neg],
         fn12 = m$table[neg,pos],
         fp21 = m$table[pos,neg],
         tp22 = m$table[pos,pos])
  y <- m$overall[c('Accuracy','Kappa')]
  names(y) <- c('acc','kappa')
  z <- m$byClass[c('Sensitivity','Specificity','Precision','F1','Balanced Accuracy')]
  names(z) <- c('sens','spec','prec','f1','balacc')
  c(x,y,z)
}

#TRNOUT 처리
#yh로 시작하는 컬럼 모두 추출
TRNtbl <- TRNOUT %>% dplyr::select(starts_with('yh'))
# 각 yh 에 대해 cnfmat()로 오분류표 작성/필요한 값만 추출
TRNtbl <- data.frame(t(map_df(TRNtbl, function(x)cnfmat(x,TRNOUT$y, positive = 'M'))))
colnames(TRNtbl) <- c('tn11','fn12','fp21','tp22',
                      'acc','kappa','sens','spec','prec','f1','balacc')
#rownames를 변수 MODEL로 저장/ 접두어 yh 제거
TRNtbl <- TRNtbl %>% rownames_to_column(var='MODEL')
TRNtbl <- mutate(TRNtbl, MODEL=substring(MODEL,3))
TRNtbl
```
```{r}
#TSTOUT 처리
#yh로 시작하는 컬럼 모두 추출
TSTtbl <- TSTOUT %>% dplyr::select(starts_with('yh'))
# 각 yh 에 대해 cnfmat()로 오분류표 작성/필요한 값만 추출
TSTtbl <- data.frame(t(map_df(TSTtbl, function(x)cnfmat(x,TSTOUT$y, positive = 'M'))))
colnames(TSTtbl) <- c('tn11','fn12','fp21','tp22',
                      'acc','kappa','sens','spec','prec','f1','balacc')
#rownames를 변수 MODEL로 저장/ 접두어 yh 제거
TSTtbl <- TSTtbl %>% rownames_to_column(var='MODEL')
TSTtbl <- mutate(TSTtbl, MODEL=substring(MODEL,3))
TSTtbl
```
```{r}
#Accuracy 비교 {xgbTree,ranger,glmnet,step,glm,svmRadial,rpart,nnet}순
ACCtbl <- data.frame(MODEL=TRNtbl$MODEL,TRNacc=TRNtbl$acc,TSTacc=TSTtbl$acc)
ggplot(ACCtbl, aes(x=reorder(MODEL,TSTacc)))+
  geom_point(aes(y=TSTacc),stat='identity', col='red')+
  geom_point(aes(y=TRNacc),stat='identity', col='blue',shape=2)+ xlab('Model')+ylab('Accuracy')+
  coord_flip()
  
```

```{r}
#Sensitivity 비교 {xgbTree,ranger,glmnet,svmRadial,step,rpart,nnet,glm}순
SENStbl <- data.frame(MODEL=TRNtbl$MODEL, TRNsens=TRNtbl$sens, TSTsens = TSTtbl$sens)
ggplot(SENStbl, aes(x=reorder(MODEL, TSTsens)))+
  geom_point(aes(y=TSTsens), stat='identity',col='red')+
  geom_point(aes(y=TRNsens), stat='identity',col='blue', shape=2)+ xlab('Model')+ylab('Sensitivity')+
  coord_flip()
                              
```


### 최적 컷오프 모형에서 오분류표 
* 최적 컷오프(closest.topleft) 모형의 성능비교
* CRDS에 coords객체가 리스트로 저장되어 있음.  
* coords의 threshold(p0, 최적 컷오프)와 TRNOUT/TSTOUT의 ph값을 비교해서 오분류표 작성



```{r}
#최적 컷오프값 추출
# CRDS(리스트)의 각 원소 첫번째값 추출
#map_df(CRDS,1), map_df(CRDS,`[[`1), lapply(CRDS,`[[`1)
p0 <- map_df(CRDS, 'threshold')
p0
```
```{r}
#TRNOUT 처리
#ph 로 시작하는 컬럼(확률예측값) 모두 추출
TRNtbl0 <- TRNOUT %>% dplyr::select(starts_with('ph'))
#yh0 생성 : ph>p0 면 'M', 아니면 'F'
TRNtbl0 <- data.frame(
  ifelse(TRNtbl0 > (p0 %>% dplyr::slice(rep(1:n(),each=nrow(TRNtbl0)))),
         'M','F')
)

# yh0으로부터 오분류표 생성
TRNtbl0 <- data.frame(t(map_df(TRNtbl0,
                            function(x)cnfmat(x,TRNOUT$y,positive = 'M'))))
colnames(TRNtbl0) <- c('tn11','fn12','fp21','tp22',
                      'acc','kappa','sens','spec','prec','f1','balacc')
#rownames를 변수 MODEL로 저장/ 접두어 yh 제거
TRNtbl0 <- TRNtbl0 %>% rownames_to_column(var='MODEL')
TRNtbl0 <- mutate(TRNtbl0, MODEL=substring(MODEL,3))
TRNtbl0

```
```{r}
#TSTOUT 처리
#ph 로 시작하는 컬럼(확률예측값) 모두 추출
TSTtbl0 <- TSTOUT %>% dplyr::select(starts_with('ph'))
#yh0 생성 : ph>p0 면 'M', 아니면 'F'
TSTtbl0 <- data.frame(
  ifelse(TSTtbl0 > (p0 %>% dplyr::slice(rep(1:n(),each=nrow(TSTtbl0)))),
         'M','F')
)

#yh0으로부터 오분류표 생성
TSTtbl0 <- data.frame(t(map_df(TSTtbl0,
                            function(x)cnfmat(x,TSTOUT$y,positive = 'M'))))
colnames(TSTtbl0) <- c('tn11','fn12','fp21','tp22',
                      'acc','kappa','sens','spec','prec','f1','balacc')
#rownames를 변수 MODEL로 저장/ 접두어 yh 제거
TSTtbl0 <- TSTtbl0 %>% rownames_to_column(var='MODEL')
TSTtbl0 <- mutate(TSTtbl0, MODEL=substring(MODEL,3))
TSTtbl0
```
```{r}
#Accuracy 비교 {xgbTree,ranger,glmnet,step,glm,svmRadial,rpart,nnet}순
ACCtbl0 <- data.frame(MODEL=TRNtbl0$MODEL,TRNacc=TRNtbl0$acc,TSTacc=TSTtbl0$acc)
ggplot(ACCtbl0, aes(x=reorder(MODEL,TSTacc)))+
  geom_point(aes(y=TSTacc),stat='identity', col='red')+
  geom_point(aes(y=TRNacc),stat='identity', col='blue',shape=2)+ xlab('Model')+ylab('Accuracy')+
  coord_flip()
```
```{r}
#Sensitivity 비교 {xgbTree,ranger,glmnet,svmRadial,step,rpart,nnet,glm}순
SENStbl0 <- data.frame(MODEL=TRNtbl0$MODEL, TRNsens=TRNtbl0$sens, TSTsens = TSTtbl0$sens)
ggplot(SENStbl0, aes(x=reorder(MODEL, TSTsens)))+
  geom_point(aes(y=TSTsens), stat='identity',col='red')+
  geom_point(aes(y=TRNsens), stat='identity',col='blue', shape=2)+ xlab('Model')+ylab('Sensitivity')+
  coord_flip()
                              
```


# 최종모형
* TST에서 최적 컷오프 모형 중 acc기준: 
    * {xgbTree, ranger, glmnet, step, glm, svmRadial, rpart, nnet순}
* 사용방법을 보이기 위해 튜닝모수가 있는 ranger를 사용하기로 함 


```{r}
Mglmnet$bestTune
```
```{r}
ctrl <- trainControl(method='none')
M <- train(RC, data=trn, method='glmnet',
           trControl = ctrl,
           tuneGrid = Mglmnet$bestTune)
coef(M$finalModel, s=M$finalModel$lambda0pt)
```
```{r}
plot(M$finalModel)
```
```{r}
plotmo::plot_glmnet(M$finalModel)
```
```{r}
trnyh <- predict(M, newdata=trn)
confusionMatrix(trnyh, trn$gnd)
```
```{r}
tstyh <- predict(M, newdata=tst)
confusionMatrix(tstyh, tst$gnd)
```


```{r}
time2 <- Sys.time()
time2

time2-time1
```
